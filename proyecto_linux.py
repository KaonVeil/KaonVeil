# -*- coding: utf-8 -*-
"""proyecto_linux.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EnDDrJybyoFbuIdinW7O9piQjRooy4jM

# **Entrenamiento del modelo con Keras (TensorFlow)**

En este paso, entrenamos un modelo simple de red neuronal convolucional (CNN) para reconocer dígitos del conjunto de datos MNIST y lo guardamos en formato .h5.
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist

# Cargar el dataset MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalizar los datos
x_train, x_test = x_train / 255.0, x_test / 255.0

# Definir la arquitectura del modelo (una red neuronal convolucional simple)
model = models.Sequential([
    layers.Reshape(target_shape=(28, 28, 1), input_shape=(28, 28)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # 10 clases para los dígitos
])

# Compilar el modelo
model.compile(optimizer='adam',
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Entrenar el modelo
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

# Guardar el modelo entrenado en formato H5
model.save('modelo_mnist.h5')

import os

# Nombre del archivo que quieres verificar
nombre_archivo = 'modelo_mnist.h5'

# Asegúrate de que el archivo existe antes de intentar obtener su tamaño
if os.path.exists(nombre_archivo):
    # Obtener el tamaño del archivo en bytes
    bytes_size = os.path.getsize(nombre_archivo)

    # Convertir a Kilobytes (KB) y Megabytes (MB) para mejor lectura
    kb_size = bytes_size / 1024
    mb_size = kb_size / 1024

    print(f"El archivo '{nombre_archivo}' pesa:")
    print(f"  {bytes_size:,} bytes")
    print(f"  {kb_size:,.2f} KB")
    print(f"  {mb_size:,.2f} MB")
else:
    print(f"El archivo '{nombre_archivo}' no se encontró. Asegúrate de que se haya guardado correctamente.")

"""# **Optimización del Modelo con TensorFlow Lite**

Ahora que tenemos el modelo entrenado, lo optimizamos para ejecutarlo en un dispositivo embebido utilizando TensorFlow Lite.

## **Conversión a TensorFlow Lite**

TensorFlow Lite reduce el tamaño del modelo y mejora el rendimiento en dispositivos con recursos limitados.

Este código convierte el modelo modelo_mnist.h5 en un modelo .tflite, mucho más ligero y eficiente para dispositivos embebidos.
"""

import tensorflow as tf

# Cargar el modelo previamente entrenado
model = tf.keras.models.load_model('modelo_mnist.h5')

# Convertir el modelo a TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Guardar el modelo convertido
with open("modelo_mnist.tflite", "wb") as f:
    f.write(tflite_model)

nombre_archivo = 'modelo_mnist.tflite'

# Asegúrate de que el archivo existe antes de intentar obtener su tamaño
if os.path.exists(nombre_archivo):
    # Obtener el tamaño del archivo en bytes
    bytes_size = os.path.getsize(nombre_archivo)

    # Convertir a Kilobytes (KB) y Megabytes (MB) para mejor lectura
    kb_size = bytes_size / 1024
    mb_size = kb_size / 1024

    print(f"El archivo '{nombre_archivo}' pesa:")
    print(f"  {bytes_size:,} bytes")
    print(f"  {kb_size:,.2f} KB")
    print(f"  {mb_size:,.2f} MB")
else:
    print(f"El archivo '{nombre_archivo}' no se encontró. Asegúrate de que se haya guardado correctamente.")

"""### **Test**"""

import tensorflow as tf
import numpy as np

# --- PASO 0: Configuración y Carga de Datos de Prueba ---
# Cargamos el dataset de MNIST solo para obtener una imagen de prueba.
(_, _), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalizar y reformatear la data de prueba (igual que como se entrenó el modelo)
# El modelo TFLite espera una entrada (None, 28, 28) de tipo float32
x_test = x_test.astype(np.float32) / 255.0

# Seleccionar una imagen de prueba (ej. el primer elemento del set de prueba)
test_image = x_test[0]
true_label = y_test[0]

# El modelo TFLite espera un "batch" (lote) de imágenes, por lo que añadimos una dimensión al inicio
# De (28, 28) a (1, 28, 28)
input_data = np.expand_dims(test_image, axis=0)


# --- PASO 1: Cargar el Modelo TFLite ---
interpreter = tf.lite.Interpreter(model_path="modelo_mnist.tflite")
interpreter.allocate_tensors()

# Obtener detalles del tensor de entrada y salida
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print("---")
print(f"Tensor de Entrada (Esperado): {input_details[0]['shape']}")
print(f"Tipo de Entrada (Esperado): {input_details[0]['dtype']}")
print("---")


# --- PASO 2: Preparar la Entrada y Ejecutar la Inferencia ---
# Asegurarse de que el input_data tenga el tipo de dato correcto
interpreter.set_tensor(input_details[0]['index'], input_data)

# Ejecutar la inferencia (predicción)
interpreter.invoke()

# Obtener la salida del modelo
output_data = interpreter.get_tensor(output_details[0]['index'])


# --- PASO 3: Interpretar la Salida ---
# La salida es una lista de probabilidades (un vector de 10 elementos)
# np.argmax encuentra el índice (la clase/dígito) con la probabilidad más alta
predicted_class = np.argmax(output_data)
confidence = np.max(output_data) * 100

print(f"Etiqueta Real (Dígito Correcto): {true_label}")
print(f"Predicción del Modelo: {predicted_class}")
print(f"Confianza de la Predicción: {confidence:.2f}%")
print("---")

# Opcional: Visualizar la imagen de prueba
import matplotlib.pyplot as plt
plt.imshow(test_image, cmap='gray')
plt.title(f"Etiqueta Real: {true_label} | Predicción: {predicted_class}")
plt.axis('off')
plt.show()

"""## **Optimización del Modelo (Cuantización)**

Para hacer que el modelo sea aún más eficiente, podemos aplicar cuantización para reducir la precisión de los pesos (de 32 bits a 8 bits, por ejemplo).

Esto reducirá aún más el tamaño del modelo y mejorará la velocidad de inferencia, a costa de una ligera pérdida de precisión.
"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model_quantized = converter.convert()

# Guardar el modelo cuantizado
with open("modelo_mnist_quantized.tflite", "wb") as f:
    f.write(tflite_model_quantized)

nombre_archivo = 'modelo_mnist_quantized.tflite'

# Asegúrate de que el archivo existe antes de intentar obtener su tamaño
if os.path.exists(nombre_archivo):
    # Obtener el tamaño del archivo en bytes
    bytes_size = os.path.getsize(nombre_archivo)

    # Convertir a Kilobytes (KB) y Megabytes (MB) para mejor lectura
    kb_size = bytes_size / 1024
    mb_size = kb_size / 1024

    print(f"El archivo '{nombre_archivo}' pesa:")
    print(f"  {bytes_size:,} bytes")
    print(f"  {kb_size:,.2f} KB")
    print(f"  {mb_size:,.2f} MB")
else:
    print(f"El archivo '{nombre_archivo}' no se encontró. Asegúrate de que se haya guardado correctamente.")

"""### **Test**"""

import time
import tensorflow as tf
import numpy as np

# --- PASO 0: Configuración y Carga de Datos de Prueba ---
# Cargamos el dataset de MNIST solo para obtener una imagen de prueba.
(_, _), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalizar y reformatear la data de prueba (igual que como se entrenó el modelo)
# El modelo TFLite espera una entrada (None, 28, 28) de tipo float32
x_test = x_test.astype(np.float32) / 255.0

# Seleccionar una imagen de prueba (ej. el primer elemento del set de prueba)
test_image = x_test[0]
true_label = y_test[0]

# El modelo TFLite espera un "batch" (lote) de imágenes, por lo que añadimos una dimensión al inicio
# De (28, 28) a (1, 28, 28)
input_data = np.expand_dims(test_image, axis=0)


# --- PASO 1: Cargar el Modelo TFLite ---
interpreter = tf.lite.Interpreter(model_path="modelo_mnist_quantized.tflite")
interpreter.allocate_tensors()

# Obtener detalles del tensor de entrada y salida
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print("---")
print(f"Tensor de Entrada (Esperado): {input_details[0]['shape']}")
print(f"Tipo de Entrada (Esperado): {input_details[0]['dtype']}")
print("---")


# --- PASO 2: Preparar la Entrada y Ejecutar la Inferencia ---
# Asegurarse de que el input_data tenga el tipo de dato correcto
interpreter.set_tensor(input_details[0]['index'], input_data)

# Ejecutar la inferencia (predicción)
start_time = time.time()
interpreter.invoke()
end_time = time.time()

# Obtener la salida del modelo
output_data = interpreter.get_tensor(output_details[0]['index'])


# --- PASO 3: Interpretar la Salida ---
# La salida es una lista de probabilidades (un vector de 10 elementos)
# np.argmax encuentra el índice (la clase/dígito) con la probabilidad más alta
predicted_class = np.argmax(output_data)
confidence = np.max(output_data) * 100

print(f"Etiqueta Real (Dígito Correcto): {true_label}")
print(f"Predicción del Modelo: {predicted_class}")
print(f"Confianza de la Predicción: {confidence:.2f}%")
print("---")
inference_time_ms = (end_time - start_time) * 1000

print(f"Tiempo de inferencia: {inference_time_ms:.3f} ms (milisegundos)")

# Opcional: Visualizar la imagen de prueba
import matplotlib.pyplot as plt
plt.imshow(test_image, cmap='gray')
plt.title(f"Etiqueta Real: {true_label} | Predicción: {predicted_class}")
plt.axis('off')
plt.show()



"""# **Procesamiento de las imagenes tomadas por la camara (python)**"""

!pip install Pillow

import tensorflow as tf
import numpy as np
from PIL import Image, ImageOps # Importar ImageOps para invertir colores
import matplotlib.pyplot as plt

# --- PASO 0: Cargar el Intérprete TFLite (necesario para saber qué espera) ---
interpreter = tf.lite.Interpreter(model_path="modelo_mnist_quantized.tflite")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape'] # Esto debería ser (1, 28, 28)
input_dtype = input_details[0]['dtype'] # Esto debería ser tf.float32

print(f"El modelo TFLite espera una entrada con forma: {input_shape} y tipo: {input_dtype}")
print("---")

# --- SIMULACIÓN: Crear una imagen de un número para la demostración ---
# En un escenario real, aquí cargarías tu imagen capturada por la cámara.
# Por ejemplo: img_raw = Image.open('ruta/a/tu/imagen_de_numero.png')
# Para esta demostración, creo una imagen de un '3' simple.
try:
    from io import BytesIO
    # Esto es solo para crear una imagen de prueba, NO es parte del flujo normal
    img_bytes = BytesIO()
    fig, ax = plt.subplots(figsize=(3,3))
    ax.text(0.5, 0.5, '1', fontsize=150, color='black', ha='center', va='center')
    ax.set_facecolor('white') # Fondo blanco
    ax.axis('off')
    fig.canvas.print_png(img_bytes)
    plt.close(fig) # Cierra la figura para que no se muestre
    img_bytes.seek(0)
    img_raw = Image.open("/content/numero.png") # Convertir a RGB para que sea consistente
    print("Imagen de prueba '3' creada con éxito.")
except Exception as e:
    print(f"Error al crear imagen de prueba: {e}. Usando una imagen simple de PIL.")
    # Fallback si el generador de imágenes falla
    img_raw = Image.new('RGB', (200, 200), color = 'white')
    from PIL import ImageDraw
    d = ImageDraw.Draw(img_raw)
    d.text((50,50), "3", fill=(0,0,0), font_size=100)


# --- PASO 1: Cargar y Mostrar la Imagen Original ---
print("1. Imagen Original (Captura de Cámara):")
plt.imshow(img_raw)
plt.title("Imagen Original")
plt.axis('off')
plt.show()


# --- PASO 2: Convertir a Escala de Grises ---
# Los modelos MNIST esperan imágenes en blanco y negro (escala de grises).
img_gray = img_raw.convert('L') # 'L' para Luminance (escala de grises)
print("\n2. Imagen en Escala de Grises:")
plt.imshow(img_gray, cmap='gray')
plt.title("Escala de Grises")
plt.axis('off')
plt.show()


# --- PASO 3: Redimensionar a 28x28 píxeles ---
# Los modelos MNIST esperan exactamente 28x28 píxeles.
# Usamos Image.LANCZOS para una buena calidad de redimensionado.
img_resized = img_gray.resize((28, 28), Image.Resampling.LANCZOS)
print("\n3. Imagen Redimensionada (28x28 píxeles):")
plt.imshow(img_resized, cmap='gray')
plt.title("Redimensionada a 28x28")
plt.axis('off')
plt.show()


# --- PASO 4: Invertir Colores (si es necesario) ---
# Los números de MNIST son BLANCOS sobre fondo NEGRO.
# Si tu cámara toma números NEGROS sobre fondo BLANCO (lo más común), debes invertir.
# Podemos hacer esto revisando el color promedio de la imagen.
# Si el promedio es alto (claro), es fondo blanco, y necesitamos invertir.
img_array_temp = np.array(img_resized)
average_pixel_value = np.mean(img_array_temp)

if average_pixel_value > 128: # Si el fondo es mayormente blanco (más de la mitad del rango 0-255)
    img_inverted = ImageOps.invert(img_resized)
    print("\n4. Colores Invertidos (Números blancos sobre fondo negro):")
    plt.imshow(img_inverted, cmap='gray')
    plt.title("Colores Invertidos")
    plt.axis('off')
    plt.show()
else:
    img_inverted = img_resized # No se necesita invertir
    print("\n4. Colores no invertidos (ya está bien o es fondo oscuro).")

# Ahora convertimos la imagen final a un array de NumPy
final_image_array = np.array(img_inverted)


# --- PASO 5: Normalizar los valores de píxeles ---
# MNIST espera valores de píxeles entre 0.0 y 1.0.
normalized_image = final_image_array.astype(np.float32) / 255.0
print(f"\n5. Valores de píxeles normalizados a entre {normalized_image.min():.2f} y {normalized_image.max():.2f}")


# --- PASO 6: Ajustar la forma para la entrada del modelo ---
# El modelo TFLite espera (1, 28, 28). 'input_data' es este array listo.
# La imagen actual es (28, 28), necesitamos añadir la dimensión del batch.
input_data_for_model = np.expand_dims(normalized_image, axis=0)

print(f"\n6. Forma final del array para el modelo: {input_data_for_model.shape}")
print(f"Tipo de dato final: {input_data_for_model.dtype}")


# --- PASO FINAL: Realizar la inferencia con el modelo TFLite ---
print("\n--- Realizando Inferencia con el Modelo TFLite ---")
interpreter.set_tensor(input_details[0]['index'], input_data_for_model)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])

predicted_class = np.argmax(output_data)
confidence = np.max(output_data) * 100

print(f"Predicción del Modelo: {predicted_class}")
print(f"Confianza de la Predicción: {confidence:.2f}%")

# Opcional: Mostrar la imagen final procesada que el modelo vio
plt.imshow(normalized_image, cmap='gray')
plt.title(f"Imagen Procesada que el Modelo Vio\nPredicción: {predicted_class}")
plt.axis('off')
plt.show()

import numpy as np
import cv2
from PIL import Image, ImageOps
import matplotlib.pyplot as plt

# Asume que ya tienes 'img_raw' cargada (tu imagen original)
# --- SIMULACIÓN (Usando una imagen grande con mucho espacio vacío) ---
# Creamos una imagen de 100x100 para simular una toma lejana.
img_raw = Image.new('RGB', (100, 100), color = 'white')
from PIL import ImageDraw
d = ImageDraw.Draw(img_raw)
# Dibujamos un número pequeño y descentrado (ej. '5' en el centro)
d.text((40, 40), "5", fill=(0,0,0), font_size=20)
# -------------------------------------------------------------------

# 1. Convertir a Escala de Grises y Array
img_gray = img_raw.convert('L')
img_array = np.array(img_gray)

# 2. Aplicar Umbral (Thresholding) e Inversión
# La clave es convertir el dígito en píxeles completamente blancos (255) y el fondo en negro (0).
# Usamos un umbral para binarizar la imagen.
# cv2.THRESH_BINARY_INV invierte la imagen (blanco sobre negro), lo que facilita el contorno.
_, thresh = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)

# --- DETECCIÓN DE CONTORNOS Y RECORTE ---

# 3. Encontrar Contornos
# Esto detecta las fronteras de los objetos blancos (nuestro número).
# cv2.RETR_EXTERNAL toma solo el contorno externo (si hay agujeros como en un '0').
# cv2.CHAIN_APPROX_SIMPLE almacena solo los puntos clave, ahorrando memoria.
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

if contours:
    # 4. Encontrar el Contorno Más Grande (Asumimos que es el número)
    # Si hay ruido, este paso es crucial para ignorarlo.
    largest_contour = max(contours, key=cv2.contourArea)

    # 5. Obtener el Bounding Box
    # (x, y) es la esquina superior izquierda, (w, h) son el ancho y alto del contorno.
    x, y, w, h = cv2.boundingRect(largest_contour)

    print(f"Bounding Box (x, y, w, h): ({x}, {y}, {w}, {h})")

    # 6. Recortar la Imagen Original Usando el Bounding Box
    # Cortamos la imagen con un pequeño margen (ej. 5 píxeles) para no cortar el número.
    margin = 5
    x1 = max(0, x - margin)
    y1 = max(0, y - margin)
    x2 = min(img_array.shape[1], x + w + margin)
    y2 = min(img_array.shape[0], y + h + margin)

    # Recorte en escala de grises original (antes del umbral)
    cropped_image_array = img_array[y1:y2, x1:x2]

    # Opcional: Centrar el número y rellenar con negro si es necesario
    # Para MNIST, la imagen debe ser cuadrada. Ajustamos el recorte para mantener la relación de aspecto.

    # 7. Redimensionar el Recorte a 28x28
    # Convertimos el array a PIL Image para usar su función de redimensionado de alta calidad
    cropped_img_pil = Image.fromarray(cropped_image_array)

    # Opcional: Invertir si el recorte es fondo blanco
    if np.mean(cropped_image_array) > 128:
        cropped_img_pil = ImageOps.invert(cropped_img_pil)

    # Redimensionar a 28x28
    final_28x28 = cropped_img_pil.resize((28, 28), Image.Resampling.LANCZOS)

    print("---")
    print("Imagen Procesada y Recortada (28x28):")
    plt.imshow(final_28x28, cmap='gray')
    plt.title("Dígito Recortado y Redimensionado")
    plt.axis('off')
    plt.show()

    # 8. Normalizar para la Entrada del Modelo
    normalized_image = np.array(final_28x28).astype(np.float32) / 255.0
    input_data_for_model = np.expand_dims(normalized_image, axis=0)

    print(f"Forma final: {input_data_for_model.shape}")

else:
    print("No se detectaron contornos. La imagen podría estar completamente vacía o ser muy ruidosa.")

"""# **Completo**"""

import numpy as np
import cv2
from PIL import Image, ImageOps
import matplotlib.pyplot as plt
import tensorflow as tf
from io import BytesIO

# Necesario para verificar el formato final.
try:
    interpreter = tf.lite.Interpreter(model_path="/content/modelo_mnist.tflite")
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    input_index = input_details[0]['index']
    output_index = output_details[0]['index']
    print("Modelo TFLite cargado.")
except Exception as e:
    print(f"Error al cargar modelo TFLite: {e}. Asegúrate de que 'modelo_mnist.tflite' exista.")
    # Usaremos una forma genérica (1, 28, 28) si no se carga el modelo.
    pass

img_size = 150
# Load the image from the file
img_raw_pil = Image.open("/content/descarga.png")

# Convert the PIL Image object to a NumPy array
img_raw = np.array(img_raw_pil)

plt.figure(figsize=(3, 3))
plt.imshow(img_raw)
plt.title("1. Imagen Original (Captura)")
plt.axis('off')
plt.show()

print(f"Forma original: {img_raw.shape}")
print("-" * 40)

# Convertir de RGB a Escala de Grises
img_gray = cv2.cvtColor(img_raw, cv2.COLOR_RGB2GRAY)

# Aplicar Umbral (Thresholding) e Inversión
# Usamos cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU para:
# 1. Binarizar (hacer completamente blanco o negro).
# 2. Invertir: El número será BLANCO (255) y el fondo NEGRO (0).
# 3. OTSU: Calcula automáticamente el mejor punto de corte (umbral) para separar el fondo del objeto.
_, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)

# Mostrar el resultado
plt.figure(figsize=(3, 3))
plt.imshow(thresh, cmap='gray')
plt.title("2. Umbralización (Contorno Blanco)")
plt.axis('off')
plt.show()

print(f"Forma después de umbral: {thresh.shape}")
print("-" * 40)

# Encontrar Contornos (las fronteras del objeto blanco)
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

if contours:
    # Seleccionar el contorno más grande (asumiendo que es el número y no ruido)
    largest_contour = max(contours, key=cv2.contourArea)

    # Obtener el Bounding Box (x, y, ancho, alto)
    x, y, w, h = cv2.boundingRect(largest_contour)

    print(f"Contorno encontrado: Bounding Box (x={x}, y={y}, w={w}, h={h})")

    # Aplicar un margen alrededor del número para no cortarlo y darle espacio
    margin = 5
    x1 = max(0, x - margin)
    y1 = max(0, y - margin)
    x2 = min(img_raw.shape[1], x + w + margin)
    y2 = min(img_raw.shape[0], y + h + margin)

    # Recortar la imagen original en escala de grises con el margen
    cropped_image = img_gray[y1:y2, x1:x2]

    # Crear una visualización del recorte en la imagen original
    img_with_box = cv2.rectangle(img_raw.copy(), (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Mostrar el resultado del recorte
    plt.figure(figsize=(3, 3))
    plt.imshow(img_with_box)
    plt.title("3. Bounding Box Detectado")
    plt.axis('off')
    plt.show()

else:
    print("ERROR: No se detectaron contornos en la imagen. Asegúrate de que el número sea visible.")
    cropped_image = img_gray # Usar imagen completa como fallback

print("-" * 40)

plt.figure(figsize=(3, 3))
plt.imshow(cropped_image)
plt.title("3. Bounding Box Detectado")
plt.axis('off')
plt.show()

# Convertir el array de NumPy recortado de nuevo a PIL Image para redimensionar con calidad
cropped_pil = Image.fromarray(cropped_image)

# Invertir Colores (si es necesario)
# Ya hicimos la inversión en el umbral, pero si recortamos de la imagen gris, podría no estar invertida.
# Para el modelo, el dígito debe ser BLANCO sobre fondo NEGRO.
if np.mean(cropped_image) > 128:
    final_inverted = ImageOps.invert(cropped_pil)
    print("Colores invertidos para que el fondo sea negro.")
else:
    final_inverted = cropped_pil

# Redimensionar a 28x28 píxeles
# Esto encoge o estira el número recortado para que encaje perfectamente en 28x28.
final_28x28 = final_inverted.resize((28, 28), Image.Resampling.LANCZOS)

# Mostrar el resultado
plt.figure(figsize=(3, 3))
plt.imshow(final_28x28, cmap='gray')
plt.title("4. Recortado y Redimensionado (28x28)")
plt.axis('off')
plt.show()

# 5. Normalizar y Añadir Dimensión de Batch
normalized_image = np.array(final_28x28).astype(np.float32) / 255.0 # Normaliza a 0.0 - 1.0
input_data_for_model = np.expand_dims(normalized_image, axis=0) # Cambia (28, 28) a (1, 28, 28)

print(f"Forma final para el modelo: {input_data_for_model.shape}")
print(f"Tipo de dato final: {input_data_for_model.dtype}")
print("-" * 40)

import matplotlib.pyplot as plt

# --- PASO FINAL: Realizar la Inferencia ---
if 'interpreter' in locals():
    interpreter.set_tensor(input_index, input_data_for_model)
    interpreter.invoke()
    output_data = interpreter.get_tensor(output_index)

    predicted_class = np.argmax(output_data)
    confidence = np.max(output_data) * 100

    print(f"Dígito Predicho: {predicted_class}")
    print(f"Confianza de la Predicción: {confidence:.2f}%")

    # Mostrar la imagen final procesada que el modelo vio
    plt.figure(figsize=(3, 3))
    plt.imshow(normalized_image, cmap='gray')
    plt.title(f"Imagen Procesada que el Modelo Vio\nPredicción: {predicted_class}")
    plt.axis('off')
    plt.show()
else:
    print("No se puede realizar la inferencia porque el modelo TFLite no se cargó correctamente.")

"""# **Procesamiento de las imagenes tomadas por la camara (C)**

# **Configuración del Entorno C para TensorFlow Lite**
"""